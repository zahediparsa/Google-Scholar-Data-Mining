{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(\"../../build/final_artilce.csv\", index_col=0)\n",
    "profs = pd.read_csv(\"../../build/professors.csv\", index_col=0)\n",
    "unis = pd.read_csv(\"../../build/universities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: calculate Deapth and Breadth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create dictionaries to map professor ID to university and university to subjects\n",
    "prof_to_univ = dict(zip(profs['id'], profs['university']))\n",
    "univ_subjects = defaultdict(lambda: defaultdict(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each article\n",
    "for _, article in articles.iterrows():\n",
    "    subjects = article['main_subject']\n",
    "    link_ids = list(map(int, article['link_ids_x'].split(',')))\n",
    "    \n",
    "    # Assign main_subject to each professor's university\n",
    "    for prof_id in link_ids:\n",
    "        university = prof_to_univ.get(prof_id)\n",
    "        if university:\n",
    "            univ_subjects[university][subjects] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate breadth and depth for each university\n",
    "breadth_depth = []\n",
    "subject_numbers = articles['main_subject'].value_counts()\n",
    "\n",
    "for university, subjects in univ_subjects.items():\n",
    "    breadth = sum(1 for subject in subjects.values() if subject > 10)\n",
    "    uni_threshold = np.sqrt(sum(subjects.values()))\n",
    "    threshold = 200\n",
    "    depth = sum(1 for count in subjects.values() if count > threshold)  # Subjects with more than the threshold number of articles\n",
    "    uni_mean_depth = sum(1 for count in subjects.values() if count > uni_threshold)\n",
    "    subject_mean_depth = sum(1 for subject, count in subjects.items() if count > np.sqrt(subject_numbers[subject]))\n",
    "    # Append the results to the breadth_depth list\n",
    "    breadth_depth.append({\n",
    "        'university': university,\n",
    "        'subjects':subjects,\n",
    "        'touch_with_10': breadth,\n",
    "        'depth_with_uni_mean': uni_mean_depth,\n",
    "        'depth_with_subject_mean': subject_mean_depth,\n",
    "        'depth_with_200': depth,\n",
    "    })\n",
    "\n",
    "# Convert the breadth_depth list to a DataFrame\n",
    "breadth_depth_df = pd.DataFrame(breadth_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = breadth_depth_df.drop(columns=['subjects'])\n",
    "results = pd.merge(unis, df, left_on='University', right_on=\"university\", how='left').drop(columns=[\"university\", \"Unnamed: 0\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../../build/universities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
